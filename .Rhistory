library(here)
setwd(here("posts/betting_variance/viz"))
#####################################################
### Some simulations of betting P&L distributions ###
#####################################################
library(ggplot2)
library(here)
setwd(here("posts/_drafts/betting_variance/viz"))
# Set a custom color palette
my_palette <- c("#233D4D", "#FF9F1C", "#41EAD4", "#FDFFFC", "#F71735")
# ---- Function to generate P&L from n bets with probability p ----
sim_bets <- function(n, p) {
# Simulate n outcomes: 1 for win, 0 for loss
outcomes <- rbinom(n, size = 1, prob = p)
odds <- 1 / p # decimal odds
# For each bet, P&L is (odds - 1) if win, -1 if loss
pl <- ifelse(outcomes == 1, odds - 1, -1)
# Return total profit or loss
total_pl <- sum(pl)
return(total_pl)
}
# ---- Function to plot m repetitions of sim_bets ----
sim_iterations_plot <- function(m, n, p, binwidth = 2) {
my_pls <- c()
for (i in 1:m) {
new_pl <- sim_bets(n, p)
my_pls <- c(my_pls, new_pl)
}
my_df <- data.frame(run = c(1:m), profit_loss = my_pls)
odds <- format(round(1 / p, 1), nsmall = 1)
plot_title <- paste("Distribution of mean after", n, "bets at odds of", odds, "(simulated", m, "times)")
ggplot(my_df, aes(x=profit_loss)) +
geom_histogram(binwidth = binwidth, fill = my_palette[1]) +
labs(x = "Profit", y = "Count", title = plot_title) +
theme(plot.title = element_text(size = 12))
}
(plot1 <- sim_iterations_plot(10000, 30, 0.5))
ggsave("mean_distribution_2.png", plot1, dpi = 600)
# Set WD to avoid error at work
# setwd("C:/Users/knghj00/Documents/Golf/Multinomial R4 Model")
# Load required libraries
library(httr)
library(jsonlite)
library(readxl)
library(dplyr)
url <- "https://feeds.datagolf.com/preds/live-tournament-stats?stats=sg_putt,sg_arg,sg_app,sg_ott,distance,accuracy,gir,&round=1&tour=pga&key=6a38380b526586b5c052d3db3bce"
response <- GET(url)
r1 <- fromJSON(content(response, "text", encoding = "UTF-8"))[['live_stats']]
url <- "https://feeds.datagolf.com/preds/live-tournament-stats?stats=sg_putt,sg_arg,sg_app,sg_ott,distance,accuracy,gir,&round=2&tour=pga&key=6a38380b526586b5c052d3db3bce"
response <- GET(url)
r2 <- fromJSON(content(response, "text", encoding = "UTF-8"))[['live_stats']]
url <- "https://feeds.datagolf.com/preds/live-tournament-stats?stats=sg_putt,sg_arg,sg_app,sg_ott,distance,accuracy,gir,&round=3&tour=pga&key=6a38380b526586b5c052d3db3bce"
response <- GET(url)
r3 <- fromJSON(content(response, "text", encoding = "UTF-8"))[['live_stats']]
url <- "https://feeds.datagolf.com/preds/live-tournament-stats?stats=sg_putt,sg_arg,sg_app,sg_ott,distance,accuracy,gir,&round=event_avg&tour=pga&key=6a38380b526586b5c052d3db3bce"
response <- GET(url)
leaderboard <- fromJSON(content(response, "text", encoding = "UTF-8"))[['live_stats']]
# Calculate stats as mean/sum of r1, r2, r3
cols_to_update <- c('accuracy', 'distance', 'gir', 'sg_app', 'sg_arg', 'sg_ott', 'sg_putt')
for (col in cols_to_update) {
leaderboard[[col]] <- rowMeans(cbind(r1[[col]], r2[[col]], r3[[col]]))
}
leaderboard[['total']] <- rowSums(cbind(r1[['round']], r2[['round']], r3[['round']]))
# Complete cases only
leaderboard <- leaderboard[complete.cases(leaderboard[,c('sg_app', 'sg_arg', 'sg_ott', 'sg_putt',
'total')]), ]
# Calculate features
leaderboard$strokes_back <- leaderboard$total - min(leaderboard$total)
leaderboard$is_leader <- ifelse(leaderboard$strokes_back==0, 1, 0)
leaderboard$strokes_ahead <- ifelse(leaderboard$strokes_back == 0, sort(leaderboard$total)[2] - leaderboard$total, 0)
leaderboard$one_back <- ifelse(leaderboard$strokes_back==1, 1, 0)
leaderboard$two_back <- ifelse(leaderboard$strokes_back==2, 1, 0)
# Calculate Kelly stakes with market regression
kelly <- function(my_odds, market_odds, bankroll, commission=0.02, regress=0.5) {
true_p <- 1 / (regress * market_odds + (1 - regress) * my_odds)
net_odds <- (market_odds - 1) * (1 - commission)
stake <- (true_p - (1 - true_p) / net_odds) * bankroll
stake <- round(stake, 2)
return(stake)
}
# Get the closing odds
manual_odds <- read.csv("C:\\Users\\johnk\\Documents\\Golf\\Datagolf\\Multinomial R4 Model\\Odds\\Wyndham Championship 2025.csv")
leaderboard <- merge(leaderboard, manual_odds[,c("player_names", "close_odds")], by.x="player_name", by.y="player_names", all.x=TRUE, all.y=FALSE)
leaderboard$close_odds[is.na(leaderboard$close_odds)] <- 100
coefficients <- c(-1.519, -1.077, -0.06, -0.906, -0.271, 0.046, 2.185,
4.418, -1.902, -1.494, -1.283, -1.487, -0.56)
leaderboard$log_close_odds <- log(leaderboard$close_odds)
selected_columns <- leaderboard[, c("strokes_back",
"is_leader",
"strokes_ahead",
"one_back",
"two_back",
"distance",
"accuracy",
"gir",
"sg_ott",
"sg_app",
"sg_arg",
"sg_putt",
"log_close_odds")]
# Initial value for my_intercept
my_intercept <- -3.4043
# Function to calculate the sum of probabilities given an intercept
calc_prob_sum <- function(intercept) {
logit <- as.vector(as.matrix(selected_columns) %*% coefficients + intercept)
exp_logit <- exp(logit)
prob <- exp_logit / (1 + exp_logit)
sum(prob)
}
# Function to be minimized by optim
objective_function <- function(intercept) {
(calc_prob_sum(intercept) - 1)^2
}
# Use optim to find the intercept that makes the sum of probabilities 1
result <- optim(par = my_intercept, fn = objective_function)
# The optimal intercept
optimal_intercept <- result$par
# Update the leaderboard with the optimal intercept
leaderboard$logit <- as.vector(as.matrix(selected_columns) %*% coefficients + optimal_intercept)
leaderboard$exp <- exp(leaderboard$logit)
leaderboard$prob <- leaderboard$exp / (1 + leaderboard$exp)
# Display the optimal intercept and the sum of probabilities
cat("Optimal intercept:", optimal_intercept, "\n")
cat("Sum of probabilities:", sum(leaderboard$prob), "\n")
leaderboard$odds <- round(1 / leaderboard$prob, 3)
leaderboard_trimmed <- leaderboard %>%
select(player_name, odds) %>%
mutate(odds = case_when(
odds < 2       ~ round(odds, 3),
odds < 5       ~ round(odds, 2),
odds < 50      ~ round(odds, 1),
TRUE           ~ round(odds, 0)
))
### This script gets closing odds and player stats from the current
### tournament, and calculates forecast odds for winner after R3
# I may just have to manually enter the closing odds for now, since
# it appears DG don't add them until after the event.
# Set WD to avoid error at work
# setwd("C:/Users/knghj00/Documents/Golf/Multinomial R4 Model")
# Load required libraries
library(httr)
library(jsonlite)
library(readxl)
library(dplyr)
url <- "https://feeds.datagolf.com/preds/live-tournament-stats?stats=sg_putt,sg_arg,sg_app,sg_ott,distance,accuracy,gir,&round=1&tour=pga&key=6a38380b526586b5c052d3db3bce"
response <- GET(url)
r1 <- fromJSON(content(response, "text", encoding = "UTF-8"))[['live_stats']]
url <- "https://feeds.datagolf.com/preds/live-tournament-stats?stats=sg_putt,sg_arg,sg_app,sg_ott,distance,accuracy,gir,&round=2&tour=pga&key=6a38380b526586b5c052d3db3bce"
response <- GET(url)
r2 <- fromJSON(content(response, "text", encoding = "UTF-8"))[['live_stats']]
url <- "https://feeds.datagolf.com/preds/live-tournament-stats?stats=sg_putt,sg_arg,sg_app,sg_ott,distance,accuracy,gir,&round=3&tour=pga&key=6a38380b526586b5c052d3db3bce"
response <- GET(url)
r3 <- fromJSON(content(response, "text", encoding = "UTF-8"))[['live_stats']]
url <- "https://feeds.datagolf.com/preds/live-tournament-stats?stats=sg_putt,sg_arg,sg_app,sg_ott,distance,accuracy,gir,&round=event_avg&tour=pga&key=6a38380b526586b5c052d3db3bce"
response <- GET(url)
leaderboard <- fromJSON(content(response, "text", encoding = "UTF-8"))[['live_stats']]
# Calculate stats as mean/sum of r1, r2, r3
cols_to_update <- c('accuracy', 'distance', 'gir', 'sg_app', 'sg_arg', 'sg_ott', 'sg_putt')
for (col in cols_to_update) {
leaderboard[[col]] <- rowMeans(cbind(r1[[col]], r2[[col]], r3[[col]]))
}
leaderboard[['total']] <- rowSums(cbind(r1[['round']], r2[['round']], r3[['round']]))
# Complete cases only
leaderboard <- leaderboard[complete.cases(leaderboard[,c('sg_app', 'sg_arg', 'sg_ott', 'sg_putt',
'total')]), ]
# Calculate features
leaderboard$strokes_back <- leaderboard$total - min(leaderboard$total)
leaderboard$is_leader <- ifelse(leaderboard$strokes_back==0, 1, 0)
leaderboard$strokes_ahead <- ifelse(leaderboard$strokes_back == 0, sort(leaderboard$total)[2] - leaderboard$total, 0)
leaderboard$one_back <- ifelse(leaderboard$strokes_back==1, 1, 0)
leaderboard$two_back <- ifelse(leaderboard$strokes_back==2, 1, 0)
# Calculate Kelly stakes with market regression
kelly <- function(my_odds, market_odds, bankroll, commission=0.02, regress=0.5) {
true_p <- 1 / (regress * market_odds + (1 - regress) * my_odds)
net_odds <- (market_odds - 1) * (1 - commission)
stake <- (true_p - (1 - true_p) / net_odds) * bankroll
stake <- round(stake, 2)
return(stake)
}
# Get the closing odds
manual_odds <- read.csv("C:\\Users\\johnk\\Documents\\Golf\\Datagolf\\Multinomial R4 Model\\Odds\\Fedex St. Jude Championship 2025.csv")
leaderboard <- merge(leaderboard, manual_odds[,c("player_names", "close_odds")], by.x="player_name", by.y="player_names", all.x=TRUE, all.y=FALSE)
leaderboard$close_odds[is.na(leaderboard$close_odds)] <- 100
coefficients <- c(-1.519, -1.077, -0.06, -0.906, -0.271, 0.046, 2.185,
4.418, -1.902, -1.494, -1.283, -1.487, -0.56)
leaderboard$log_close_odds <- log(leaderboard$close_odds)
selected_columns <- leaderboard[, c("strokes_back",
"is_leader",
"strokes_ahead",
"one_back",
"two_back",
"distance",
"accuracy",
"gir",
"sg_ott",
"sg_app",
"sg_arg",
"sg_putt",
"log_close_odds")]
# Initial value for my_intercept
my_intercept <- -3.4043
# Function to calculate the sum of probabilities given an intercept
calc_prob_sum <- function(intercept) {
logit <- as.vector(as.matrix(selected_columns) %*% coefficients + intercept)
exp_logit <- exp(logit)
prob <- exp_logit / (1 + exp_logit)
sum(prob)
}
# Function to be minimized by optim
objective_function <- function(intercept) {
(calc_prob_sum(intercept) - 1)^2
}
# Use optim to find the intercept that makes the sum of probabilities 1
result <- optim(par = my_intercept, fn = objective_function)
# The optimal intercept
optimal_intercept <- result$par
# Update the leaderboard with the optimal intercept
leaderboard$logit <- as.vector(as.matrix(selected_columns) %*% coefficients + optimal_intercept)
leaderboard$exp <- exp(leaderboard$logit)
leaderboard$prob <- leaderboard$exp / (1 + leaderboard$exp)
# Display the optimal intercept and the sum of probabilities
cat("Optimal intercept:", optimal_intercept, "\n")
cat("Sum of probabilities:", sum(leaderboard$prob), "\n")
leaderboard$odds <- round(1 / leaderboard$prob, 3)
leaderboard_trimmed <- leaderboard %>%
select(player_name, odds) %>%
mutate(odds = case_when(
odds < 2       ~ round(odds, 3),
odds < 5       ~ round(odds, 2),
odds < 50      ~ round(odds, 1),
TRUE           ~ round(odds, 0)
))
View(leaderboard_trimmed)
kelly(2.13, 2.76, 3446)
kelly(20.3, 25, 3446)
### Grabs the closing odds for current events (need to run on a Thursday before round ends) ###
library(httr)
library(jsonlite)
setwd("C:/Users/johnk/Documents/Golf/Datagolf/Multinomial R4 Model/Odds")
url <- 'https://feeds.datagolf.com/betting-tools/outrights?tour=pga&market=win&odds_format=decimal&file_format=json&key=6a38380b526586b5c052d3db3bce'
response <- GET(url)
if (http_status(response)$category == "Success") {
# Parse JSON content and return
api_data <- content(response, "text", encoding = "UTF-8")
} else {
# Return NULL or handle error as needed
warning(paste("Failed to retrieve data for tour:", tour, "event_id:", event_id, "year:", year))
}
json_data <- fromJSON(api_data)
event_name <- json_data[['event_name']]
last_updated <- json_data[['last_updated']]
player_names <- json_data[['odds']][['player_name']]
pinnacle <- json_data[['odds']][['pinnacle']]
draftkings <- json_data[['odds']][['draftkings']]
fanduel <- json_data[['odds']][['fanduel']]
williamhill <- json_data[['odds']][['williamhill']]
my_odds <- data.frame(player_names, pinnacle, draftkings, fanduel, williamhill)
my_odds$close_odds <- pmax(my_odds$pinnacle, my_odds$draftkings, my_odds$fanduel, my_odds$williamhill, na.rm=TRUE)
year <- substr(last_updated, 1, 4)
filename <- paste0(event_name, ' ', year, '.csv')
write.csv(my_odds, filename, row.names=FALSE)
### This script gets closing odds and player stats from the current
### tournament, and calculates forecast odds for winner after R3
# I may just have to manually enter the closing odds for now, since
# it appears DG don't add them until after the event.
# Set WD to avoid error at work
# setwd("C:/Users/knghj00/Documents/Golf/Multinomial R4 Model")
# Load required libraries
library(httr)
library(jsonlite)
library(readxl)
library(dplyr)
url <- "https://feeds.datagolf.com/preds/live-tournament-stats?stats=sg_putt,sg_arg,sg_app,sg_ott,distance,accuracy,gir,&round=1&tour=pga&key=6a38380b526586b5c052d3db3bce"
response <- GET(url)
r1 <- fromJSON(content(response, "text", encoding = "UTF-8"))[['live_stats']]
url <- "https://feeds.datagolf.com/preds/live-tournament-stats?stats=sg_putt,sg_arg,sg_app,sg_ott,distance,accuracy,gir,&round=2&tour=pga&key=6a38380b526586b5c052d3db3bce"
response <- GET(url)
r2 <- fromJSON(content(response, "text", encoding = "UTF-8"))[['live_stats']]
url <- "https://feeds.datagolf.com/preds/live-tournament-stats?stats=sg_putt,sg_arg,sg_app,sg_ott,distance,accuracy,gir,&round=3&tour=pga&key=6a38380b526586b5c052d3db3bce"
response <- GET(url)
r3 <- fromJSON(content(response, "text", encoding = "UTF-8"))[['live_stats']]
url <- "https://feeds.datagolf.com/preds/live-tournament-stats?stats=sg_putt,sg_arg,sg_app,sg_ott,distance,accuracy,gir,&round=event_avg&tour=pga&key=6a38380b526586b5c052d3db3bce"
response <- GET(url)
leaderboard <- fromJSON(content(response, "text", encoding = "UTF-8"))[['live_stats']]
# Calculate stats as mean/sum of r1, r2, r3
cols_to_update <- c('accuracy', 'distance', 'gir', 'sg_app', 'sg_arg', 'sg_ott', 'sg_putt')
for (col in cols_to_update) {
leaderboard[[col]] <- rowMeans(cbind(r1[[col]], r2[[col]], r3[[col]]))
}
leaderboard[['total']] <- rowSums(cbind(r1[['round']], r2[['round']], r3[['round']]))
# Complete cases only
leaderboard <- leaderboard[complete.cases(leaderboard[,c('sg_app', 'sg_arg', 'sg_ott', 'sg_putt',
'total')]), ]
# Calculate features
leaderboard$strokes_back <- leaderboard$total - min(leaderboard$total)
leaderboard$is_leader <- ifelse(leaderboard$strokes_back==0, 1, 0)
leaderboard$strokes_ahead <- ifelse(leaderboard$strokes_back == 0, sort(leaderboard$total)[2] - leaderboard$total, 0)
leaderboard$one_back <- ifelse(leaderboard$strokes_back==1, 1, 0)
leaderboard$two_back <- ifelse(leaderboard$strokes_back==2, 1, 0)
# Calculate Kelly stakes with market regression
kelly <- function(my_odds, market_odds, bankroll, commission=0.02, regress=0.5) {
true_p <- 1 / (regress * market_odds + (1 - regress) * my_odds)
net_odds <- (market_odds - 1) * (1 - commission)
stake <- (true_p - (1 - true_p) / net_odds) * bankroll
stake <- round(stake, 2)
return(stake)
}
# Get the closing odds
manual_odds <- read.csv("C:\\Users\\johnk\\Documents\\Golf\\Datagolf\\Multinomial R4 Model\\Odds\\BMW Championship 2025.csv")
leaderboard <- merge(leaderboard, manual_odds[,c("player_names", "close_odds")], by.x="player_name", by.y="player_names", all.x=TRUE, all.y=FALSE)
leaderboard$close_odds[is.na(leaderboard$close_odds)] <- 100
coefficients <- c(-1.519, -1.077, -0.06, -0.906, -0.271, 0.046, 2.185,
4.418, -1.902, -1.494, -1.283, -1.487, -0.56)
leaderboard$log_close_odds <- log(leaderboard$close_odds)
selected_columns <- leaderboard[, c("strokes_back",
"is_leader",
"strokes_ahead",
"one_back",
"two_back",
"distance",
"accuracy",
"gir",
"sg_ott",
"sg_app",
"sg_arg",
"sg_putt",
"log_close_odds")]
# Initial value for my_intercept
my_intercept <- -3.4043
# Function to calculate the sum of probabilities given an intercept
calc_prob_sum <- function(intercept) {
logit <- as.vector(as.matrix(selected_columns) %*% coefficients + intercept)
exp_logit <- exp(logit)
prob <- exp_logit / (1 + exp_logit)
sum(prob)
}
# Function to be minimized by optim
objective_function <- function(intercept) {
(calc_prob_sum(intercept) - 1)^2
}
# Use optim to find the intercept that makes the sum of probabilities 1
result <- optim(par = my_intercept, fn = objective_function)
# The optimal intercept
optimal_intercept <- result$par
# Update the leaderboard with the optimal intercept
leaderboard$logit <- as.vector(as.matrix(selected_columns) %*% coefficients + optimal_intercept)
leaderboard$exp <- exp(leaderboard$logit)
leaderboard$prob <- leaderboard$exp / (1 + leaderboard$exp)
# Display the optimal intercept and the sum of probabilities
cat("Optimal intercept:", optimal_intercept, "\n")
cat("Sum of probabilities:", sum(leaderboard$prob), "\n")
leaderboard$odds <- round(1 / leaderboard$prob, 3)
leaderboard_trimmed <- leaderboard %>%
select(player_name, odds) %>%
mutate(odds = case_when(
odds < 2       ~ round(odds, 3),
odds < 5       ~ round(odds, 2),
odds < 50      ~ round(odds, 1),
TRUE           ~ round(odds, 0)
))
View(leaderboard_trimmed)
kelly(2.78, 3.15, 3205)
quarto::quarto_render("dashboards/pl-table/index.qmd")
install.packages("quarto")
1.29+1.22+0.87+0.53+0.75+1.72+0.1+0.92+0.07+0.86+0.75+2.18+0.33+2.32+1.11+0.19
12/17
install.packages("rmarkdown")
install.packages("gt")
install.packages("shiny")
install.packages("DBI")
install.packages("RSQlite")
install.packages("RSQLite")
install.packages("stringr")
install.packages("readr")
install.packages("renv")
renv::dependencies()
pkgs <- unique(renv::dependencies()$Package)
pkgs <- pkgs[!is.na(pkgs)]
install.packages(pkgs)
31.7+28.7+23.6+21.3
###################################################
### Download daily Elo ratings from clubelo.com ###
###################################################
# ----- Load packages -----
library(lubridate)
library(here)
# ---- Look for existing Elo files in data folder ----
data_dir <- here("data/elo")
if (!dir.exists(data_dir)) dir.create(data_dir)
existing_files <- list.files(data_dir, pattern = "^eloratings_\\d{4}-\\d{2}-\\d{2}\\.csv$", full.names = FALSE)
start_date <- NA # Set to "YYYY-MM-DD" to override
# ---- Set start date from last existing file ----
if (is.na(start_date)) {
if (length(existing_files) > 0) {
dates <- as.Date(sub("eloratings_(\\d{4}-\\d{2}-\\d{2})\\.csv", "\\1", existing_files))
start_date <- max(dates) + 1  # Continue from the next day
} else {
start_date <- as.Date("1940-01-01")  # Default start date
}
}
# ---- Set end date as today's date ----
end_date <- Sys.Date()
# ---- Generate sequence of dates to download ----
if (start_date > end_date) {
stop("Start date is after end date — nothing to download.")
}
download_dates <- as.character(seq(start_date, end_date, by = "day"))
# ---- Download daily Elo ratings ----
for (mydate in download_dates) {
message("Downloading Elo ratings for ", mydate)
api_url <- paste0("http://api.clubelo.com/", mydate)
filename <- paste0("eloratings_", mydate, ".csv")
filepath <- file.path(data_dir, filename)
# Only download if the file doesn’t already exist
if (!file.exists(filepath)) {
tryCatch({
download.file(api_url, destfile = filepath, quiet = TRUE)
}, error = function(e) {
warning("Failed to download data for ", mydate, ": ", e$message)
})
} else {
message("File already exists for ", mydate, ", skipping.")
}
}
warnings()
###################################################
### Download daily Elo ratings from clubelo.com ###
###################################################
# ----- Load packages -----
library(lubridate)
library(here)
# ---- Look for existing Elo files in data folder ----
data_dir <- here("data/elo")
if (!dir.exists(data_dir)) dir.create(data_dir)
existing_files <- list.files(data_dir, pattern = "^eloratings_\\d{4}-\\d{2}-\\d{2}\\.csv$", full.names = FALSE)
start_date <- NA # Set to "YYYY-MM-DD" to override
# ---- Set start date from last existing file ----
if (is.na(start_date)) {
if (length(existing_files) > 0) {
dates <- as.Date(sub("eloratings_(\\d{4}-\\d{2}-\\d{2})\\.csv", "\\1", existing_files))
start_date <- max(dates) + 1  # Continue from the next day
} else {
start_date <- as.Date("1940-01-01")  # Default start date
}
}
# ---- Set end date as today's date ----
end_date <- Sys.Date()
# ---- Generate sequence of dates to download ----
if (start_date > end_date) {
stop("Start date is after end date — nothing to download.")
}
download_dates <- as.character(seq(start_date, end_date, by = "day"))
# ---- Download daily Elo ratings ----
for (mydate in download_dates) {
message("Downloading Elo ratings for ", mydate)
api_url <- paste0("http://api.clubelo.com/", mydate)
filename <- paste0("eloratings_", mydate, ".csv")
filepath <- file.path(data_dir, filename)
# Only download if the file doesn’t already exist
if (!file.exists(filepath)) {
tryCatch({
download.file(api_url, destfile = filepath, quiet = TRUE)
}, error = function(e) {
warning("Failed to download data for ", mydate, ": ", e$message)
})
} else {
message("File already exists for ", mydate, ", skipping.")
}
}
warnings()
log(1.5)
log(5)
0.8/0.2
0.2/0.8
log(4)
log(0.25)
1.386*2
*0.005
2.772*0.005
0.026/0.11
0.024/0.11
?ggplot
??ggplot
library(httr)
library(jsonlite)
setwd("~/Projects/Sport/Golf/Datagolf/Multinomial R4 Model/Odds")
library(httr)
library(jsonlite)
setwd("~/Sport/Golf/Datagolf/Multinomial R4 Model/Odds")
url <- 'https://feeds.datagolf.com/betting-tools/outrights?tour=pga&market=win&odds_format=decimal&file_format=json&key=6a38380b526586b5c052d3db3bce'
response <- GET(url)
if (http_status(response)$category == "Success") {
# Parse JSON content and return
api_data <- content(response, "text", encoding = "UTF-8")
} else {
# Return NULL or handle error as needed
warning(paste("Failed to retrieve data for tour:", tour, "event_id:", event_id, "year:", year))
}
json_data <- fromJSON(api_data)
event_name <- json_data[['event_name']]
last_updated <- json_data[['last_updated']]
player_names <- json_data[['odds']][['player_name']]
pinnacle <- json_data[['odds']][['pinnacle']]
draftkings <- json_data[['odds']][['draftkings']]
fanduel <- json_data[['odds']][['fanduel']]
williamhill <- json_data[['odds']][['williamhill']]
my_odds <- data.frame(player_names, pinnacle, draftkings, fanduel, williamhill)
my_odds$close_odds <- pmax(my_odds$pinnacle, my_odds$draftkings, my_odds$fanduel, my_odds$williamhill, na.rm=TRUE)
year <- substr(last_updated, 1, 4)
filename <- paste0(event_name, ' ', year, '.csv')
write.csv(my_odds, filename, row.names=FALSE)
getwd()
