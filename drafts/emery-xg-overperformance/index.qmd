---
title: "Unai Emery: the xG whisperer"
image: emery.jpg
author: "John Knight"
date: 2026-01-03
date-format: "D MMMM YYYY"
description: "Part one: Why should anyone care about xG, and which managers consistently outperform xG?"
format:
  html:
    title-block-categories: true
    css: ../../styles.css
categories: ["football", "statistics"]
execute: 
  echo: false
  eval: true
engine: knitr
editor: source
draft: true
# resources:


---

*Frame this as part one: Emery, why do we care about xg, and which managers are the best/worst compared to xg? Make it more robust: include variance, show results as z scores, show results for league games only, etc.*

Anyone who has taken a passing interest at the underlying statistics from the current Premier League table will be aware that Aston Villa have been sustaining one of the all-time expected goals (xG) overperformances. Depending on your slant, either Unai Emery is a genius who defies the laws of xG, or Villa have been an absurdly fortunate side who are due a big regression.

*Show current PL table here*

The truth probably lies somewhere between those two poles, but why should we even care about xG in the first place?

Despite xG being around for a fairly long time now, it continues to attract criticism from those who either don't understand it, or hold it to unfair standards. I recommend Scott Willis' [recent article](https://www.pythonfootball.com/p/which-xg-data-should-you-trust) discussing some common misunderstndings.

In statistical circles you will often hear George Box's maxim, "all models are wrong, but some are useful". And this really is an important concept to emphasize. Just because an xG model says a chance was worth 0.4 goals, or that a team had 1.3 goals' worth of chances during a game, does not make that some ground source of truth. Anyone can watch the game with their eyes and judge that a chance is better, or worse, than the xG model rates it.

But is xG useful? One way to judge this is to look at whether xG is predictive. 

My dataset for this study uses FBRef data from the 'big five' European leagues (England, Spain, Italy, Germany and France), plus UEFA competitions, in the seasons 2017-2018 to 2024-2025. FBRef uses Opta's xG model; there are others to choose from, and [Python Football Review](https://www.pythonfootball.com/p/which-xg-data-should-you-trust) makes a nice comparison here.

I ran regressions across all teams, predicting their points-per-game over the remainder of the season after each match.


::: {.image-block .max-70}
![](viz/slr_coefs.png){fig-cap="SLR = simple linear regression. Big 5 European leagues 2017 to 2025 (2019-2020 Ligue 1 excluded due to COVID-shortened season)."}
:::

The following two plots compare the R^2 values for three different variables used as predictors after each game: points per game, goal difference (GD) per game, and xg per game. R^2 tells us how much of the variance can be explained by the model, so higher = a more powerful predictor.

The first plot compares the R^2 for three separate regressions using each variable on its own:

::: {.image-block .max-70}
![](viz/slr_r2.png){fig-cap = "SLR = simple linear regression. R^2 measures the proportion of the variance in the dependent variable (future PPG) explained by each model.}
:::

So we can see that xG is the best predictor, followed by GD, then points. But the three lines track each other fairly closely: the variables each act as a reasonable proxy for team strength, if you literally didn't know anything else about each team.

However, look at the second plot which shows the marginal R^2 from a multiple linear regression. In other words, this plot charts the extra predictive power that each variable offers when used in concert with the other two.

::: {.image-block .max-70}
![](viz/mlr_marginal_r2.png){fig-cap = "MLR = multiple linear regression. Marginal R^2 measures the additional proportion of the variance explained when each independent variable is added to the simpler model.}
:::

It is clear that xG explains a lot more of the variance than points or GD. This is why people tend to use it as a quick & dirty indicator of which teams have been lucky or unlucky so far each season.

And so we return to Aston Villa. What can we expect from them in the second half of this season? Based on the above, it would be fair to conclude that Villa's xG (*nth place*) is a much better indicator than their league position (*nth place*). But what about the Emery factor? Is there something in his tactics that enables his teams to defy xG?

An obvious starting point is to compare xG with actual goals across the seasons in the dataset. *Own goals and calibration*

First, I plotted attacking overperformance (x axis) against defensive overperformance (y axis). So the top right quadrant of this plot is the place to be.

*Plot with totals*

Maybe this rewards quantity so plot z-scores:

*Also plot with z-scores*

The results aren't overly surprising: Pep Guardiola stands miles clear a overperforming xG in attack, while Diego Simeone and Carlo Ancelotti excel on the defensive end. To emphasize: this measures the difference between xG and actual goals scored/conceded, so these managers already have elite teams putting up elite xg numbers, and then they additionally beat their xg by more than everyone else as well.

As you will have noticed, Unai Emery sits in between these managers, exceeding his xg in both attack and defence. In fact he sits third in this table (*does he?*):

*Show the top 5 managers in a table. Include SE/CI*

*Conclusion: Emery is one of the best managers versus xG, which we have seen is predictive on a team-season level. In the next part we will break down Emery's past performance by club, and drill down a little bit on where this xG overperformance comes from, including which players have overperformed their xG the most under Emery, and how Emery's xG overperformance changes by game state.*